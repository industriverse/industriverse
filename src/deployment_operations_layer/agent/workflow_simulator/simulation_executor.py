"""
Simulation Executor

This module is responsible for executing simulation scenarios for the Workflow Simulator Agent.
It runs the generated scenarios in a controlled environment, simulating network conditions,
resource constraints, and load profiles to test deployments under various conditions.
"""

import logging
import time
import uuid
import random
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

class SimulationExecutor:
    """
    Executes simulation scenarios to test deployments under various conditions.
    
    This class runs the simulation scenarios generated by the SimulationScenarioGenerator,
    applying the specified network conditions, resource constraints, and load profiles
    to test how deployments perform under different circumstances.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize the Simulation Executor.
        
        Args:
            config: Configuration dictionary for the executor
        """
        self.config = config or {}
        
        # Initialize execution engines
        self.network_simulator = NetworkSimulator(self.config.get("network_simulator", {}))
        self.resource_simulator = ResourceSimulator(self.config.get("resource_simulator", {}))
        self.load_generator = LoadGenerator(self.config.get("load_generator", {}))
        
        # Execution settings
        self.default_execution_time = self.config.get("default_execution_time", 300)  # 5 minutes
        self.sampling_interval = self.config.get("sampling_interval", 5)  # 5 seconds
        
        logger.info("Simulation Executor initialized")
    
    def execute_simulation(self, 
                          scenarios: List[Dict[str, Any]],
                          deployment_manifest: Dict[str, Any],
                          environment_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute a set of simulation scenarios.
        
        Args:
            scenarios: List of simulation scenarios to execute
            deployment_manifest: The deployment manifest being tested
            environment_config: Configuration of the target environment
            
        Returns:
            Dictionary containing simulation execution results
        """
        simulation_results = {
            "id": str(uuid.uuid4()),
            "timestamp": time.time(),
            "deployment_manifest_id": deployment_manifest.get("id", "unknown"),
            "environment": environment_config.get("name", "unknown"),
            "scenario_results": [],
            "overall_metrics": {},
            "execution_time": 0
        }
        
        start_time = time.time()
        
        # Execute each scenario
        for scenario in scenarios:
            logger.info(f"Executing scenario: {scenario['id']} - {scenario['description']}")
            
            scenario_result = self._execute_scenario(
                scenario, 
                deployment_manifest,
                environment_config
            )
            
            simulation_results["scenario_results"].append(scenario_result)
        
        # Calculate overall metrics
        simulation_results["overall_metrics"] = self._calculate_overall_metrics(
            simulation_results["scenario_results"]
        )
        
        # Record execution time
        simulation_results["execution_time"] = time.time() - start_time
        
        logger.info(f"Completed execution of {len(scenarios)} scenarios in "
                   f"{simulation_results['execution_time']:.2f} seconds")
        
        return simulation_results
    
    def _execute_scenario(self,
                         scenario: Dict[str, Any],
                         deployment_manifest: Dict[str, Any],
                         environment_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute a single simulation scenario.
        
        Args:
            scenario: The scenario to execute
            deployment_manifest: The deployment manifest being tested
            environment_config: Configuration of the target environment
            
        Returns:
            Dictionary containing scenario execution results
        """
        scenario_id = scenario["id"]
        execution_time = scenario.get("duration_seconds", self.default_execution_time)
        
        # Initialize result structure
        result = {
            "scenario_id": scenario_id,
            "start_time": time.time(),
            "end_time": None,
            "duration": 0,
            "status": "running",
            "metrics": {
                "network": [],
                "resources": [],
                "load": [],
                "application": []
            },
            "events": [],
            "errors": [],
            "success": False
        }
        
        try:
            # Configure simulators according to scenario
            self.network_simulator.configure(scenario["network_conditions"])
            self.resource_simulator.configure(scenario["resource_availability"])
            self.load_generator.configure(scenario["load_profile"])
            
            # Start simulators
            self.network_simulator.start()
            self.resource_simulator.start()
            self.load_generator.start()
            
            # Record start event
            self._record_event(result, "simulation_started", {
                "scenario_id": scenario_id,
                "description": scenario["description"]
            })
            
            # Simulate deployment
            deployment_result = self._simulate_deployment(
                deployment_manifest,
                environment_config,
                scenario
            )
            
            if not deployment_result["success"]:
                self._record_event(result, "deployment_failed", {
                    "reason": deployment_result["reason"],
                    "details": deployment_result["details"]
                })
                result["errors"].append({
                    "type": "deployment_failure",
                    "message": deployment_result["reason"],
                    "details": deployment_result["details"]
                })
                result["success"] = False
                return self._finalize_result(result)
            
            self._record_event(result, "deployment_succeeded", {
                "deployment_time": deployment_result["deployment_time"]
            })
            
            # Run the simulation for the specified duration
            num_samples = execution_time // self.sampling_interval
            
            for i in range(num_samples):
                # Sleep for sampling interval
                time.sleep(self.sampling_interval)
                
                # Collect metrics
                network_metrics = self.network_simulator.get_metrics()
                resource_metrics = self.resource_simulator.get_metrics()
                load_metrics = self.load_generator.get_metrics()
                app_metrics = self._collect_application_metrics(deployment_result["deployment"])
                
                # Record metrics
                result["metrics"]["network"].append({
                    "timestamp": time.time(),
                    **network_metrics
                })
                
                result["metrics"]["resources"].append({
                    "timestamp": time.time(),
                    **resource_metrics
                })
                
                result["metrics"]["load"].append({
                    "timestamp": time.time(),
                    **load_metrics
                })
                
                result["metrics"]["application"].append({
                    "timestamp": time.time(),
                    **app_metrics
                })
                
                # Check for errors or events
                if random.random() < 0.05:  # 5% chance of an event
                    event_type = random.choice(["info", "warning", "error"])
                    if event_type == "error":
                        error = self._generate_random_error()
                        self._record_event(result, "error_occurred", error)
                        result["errors"].append(error)
                    else:
                        self._record_event(result, f"{event_type}_event", {
                            "message": f"Random {event_type} event for testing"
                        })
            
            # Determine success based on errors
            result["success"] = len(result["errors"]) == 0
            
            # Record completion event
            self._record_event(result, "simulation_completed", {
                "success": result["success"],
                "error_count": len(result["errors"])
            })
            
        except Exception as e:
            logger.exception(f"Error executing scenario {scenario_id}")
            self._record_event(result, "simulation_error", {
                "error": str(e)
            })
            result["errors"].append({
                "type": "simulation_error",
                "message": str(e),
                "details": {
                    "exception_type": type(e).__name__
                }
            })
            result["success"] = False
        
        finally:
            # Stop simulators
            try:
                self.network_simulator.stop()
                self.resource_simulator.stop()
                self.load_generator.stop()
            except Exception as e:
                logger.exception(f"Error stopping simulators for scenario {scenario_id}")
            
            # Finalize result
            return self._finalize_result(result)
    
    def _simulate_deployment(self,
                            deployment_manifest: Dict[str, Any],
                            environment_config: Dict[str, Any],
                            scenario: Dict[str, Any]) -> Dict[str, Any]:
        """
        Simulate the deployment process.
        
        Args:
            deployment_manifest: The deployment manifest
            environment_config: The environment configuration
            scenario: The simulation scenario
            
        Returns:
            Dictionary with deployment simulation results
        """
        # In a real implementation, this would interact with a deployment simulator
        # For now, we'll simulate the process with random success/failure
        
        # Extract relevant information
        network_conditions = scenario["network_conditions"]
        resource_availability = scenario["resource_availability"]
        
        # Calculate success probability based on conditions
        base_success_prob = 0.9  # 90% success rate in normal conditions
        
        # Network factors
        network_factor = 1.0
        if network_conditions["latency_ms"] > 50:
            network_factor *= 0.9
        if network_conditions["packet_loss_percent"] > 1:
            network_factor *= 0.8
        
        # Resource factors
        resource_factor = 1.0
        if resource_availability["cpu_available_percent"] < 50:
            resource_factor *= 0.8
        if resource_availability["memory_available_percent"] < 50:
            resource_factor *= 0.8
        
        # Calculate final success probability
        success_prob = base_success_prob * network_factor * resource_factor
        
        # Simulate deployment time
        base_time = 30  # 30 seconds base deployment time
        network_time_factor = 1 + (network_conditions["latency_ms"] / 100)
        resource_time_factor = 1 + ((100 - resource_availability["cpu_available_percent"]) / 100)
        deployment_time = base_time * network_time_factor * resource_time_factor
        
        # Simulate success/failure
        if random.random() < success_prob:
            return {
                "success": True,
                "deployment_time": deployment_time,
                "deployment": {
                    "id": str(uuid.uuid4()),
                    "status": "deployed",
                    "manifest": deployment_manifest
                }
            }
        else:
            # Generate a random failure reason
            failure_reasons = [
                ("resource_exhausted", "Insufficient memory available for deployment"),
                ("network_timeout", "Network timeout during container image pull"),
                ("validation_failed", "Deployment validation failed"),
                ("dependency_missing", "Required dependency not available in environment")
            ]
            failure = random.choice(failure_reasons)
            
            return {
                "success": False,
                "reason": failure[0],
                "details": {
                    "message": failure[1],
                    "component": random.choice(["container", "service", "volume", "network"])
                }
            }
    
    def _collect_application_metrics(self, deployment: Dict[str, Any]) -> Dict[str, Any]:
        """
        Collect application-specific metrics from the deployed application.
        
        Args:
            deployment: The deployment information
            
        Returns:
            Dictionary of application metrics
        """
        # In a real implementation, this would collect actual metrics
        # For now, we'll generate random metrics
        
        return {
            "response_time_ms": random.uniform(10, 500),
            "throughput_rps": random.uniform(10, 1000),
            "error_rate_percent": random.uniform(0, 5),
            "cpu_usage_percent": random.uniform(10, 90),
            "memory_usage_percent": random.uniform(10, 90),
            "active_connections": random.randint(1, 1000)
        }
    
    def _record_event(self, result: Dict[str, Any], event_type: str, details: Dict[str, Any]):
        """
        Record an event in the simulation results.
        
        Args:
            result: The result dictionary to update
            event_type: Type of event
            details: Event details
        """
        result["events"].append({
            "timestamp": time.time(),
            "type": event_type,
            "details": details
        })
    
    def _generate_random_error(self) -> Dict[str, Any]:
        """
        Generate a random error for simulation purposes.
        
        Returns:
            Dictionary with error information
        """
        error_types = [
            ("network_error", "Network connection failed"),
            ("resource_error", "Resource limit exceeded"),
            ("application_error", "Application crashed"),
            ("timeout_error", "Operation timed out")
        ]
        
        error_type, message = random.choice(error_types)
        
        return {
            "type": error_type,
            "message": message,
            "details": {
                "severity": random.choice(["low", "medium", "high"]),
                "component": random.choice(["network", "compute", "storage", "application"])
            }
        }
    
    def _finalize_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Finalize the simulation result.
        
        Args:
            result: The result dictionary to finalize
            
        Returns:
            Finalized result dictionary
        """
        result["end_time"] = time.time()
        result["duration"] = result["end_time"] - result["start_time"]
        result["status"] = "completed"
        
        # Calculate summary metrics
        if result["metrics"]["application"]:
            app_metrics = result["metrics"]["application"]
            result["summary"] = {
                "avg_response_time_ms": sum(m["response_time_ms"] for m in app_metrics) / len(app_metrics),
                "avg_throughput_rps": sum(m["throughput_rps"] for m in app_metrics) / len(app_metrics),
                "avg_error_rate_percent": sum(m["error_rate_percent"] for m in app_metrics) / len(app_metrics),
                "max_cpu_usage_percent": max(m["cpu_usage_percent"] for m in app_metrics),
                "max_memory_usage_percent": max(m["memory_usage_percent"] for m in app_metrics),
                "max_active_connections": max(m["active_connections"] for m in app_metrics)
            }
        
        return result
    
    def _calculate_overall_metrics(self, scenario_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Calculate overall metrics across all scenarios.
        
        Args:
            scenario_results: List of scenario results
            
        Returns:
            Dictionary of overall metrics
        """
        if not scenario_results:
            return {}
        
        # Count successes
        success_count = sum(1 for r in scenario_results if r["success"])
        success_rate = success_count / len(scenario_results)
        
        # Collect all errors
        all_errors = []
        for result in scenario_results:
            all_errors.extend(result.get("errors", []))
        
        # Calculate average metrics if available
        avg_metrics = {}
        if all(("summary" in r) for r in scenario_results):
            for key in scenario_results[0]["summary"].keys():
                avg_metrics[key] = sum(r["summary"][key] for r in scenario_results) / len(scenario_results)
        
        return {
            "success_rate": success_rate,
            "total_scenarios": len(scenario_results),
            "successful_scenarios": success_count,
            "failed_scenarios": len(scenario_results) - success_count,
            "total_errors": len(all_errors),
            "error_types": self._count_error_types(all_errors),
            "avg_metrics": avg_metrics,
            "total_duration": sum(r["duration"] for r in scenario_results)
        }
    
    def _count_error_types(self, errors: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        Count occurrences of each error type.
        
        Args:
            errors: List of error dictionaries
            
        Returns:
            Dictionary mapping error types to counts
        """
        error_counts = {}
        for error in errors:
            error_type = error.get("type", "unknown")
            error_counts[error_type] = error_counts.get(error_type, 0) + 1
        
        return error_counts


class NetworkSimulator:
    """
    Simulates network conditions for deployment testing.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize the Network Simulator.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config or {}
        self.current_config = {}
        self.running = False
    
    def configure(self, network_config: Dict[str, Any]):
        """
        Configure the network simulator.
        
        Args:
            network_config: Network configuration to apply
        """
        self.current_config = network_config
    
    def start(self):
        """Start the network simulator."""
        self.running = True
        logger.info(f"Started network simulator with config: {self.current_config}")
    
    def stop(self):
        """Stop the network simulator."""
        self.running = False
        logger.info("Stopped network simulator")
    
    def get_metrics(self) -> Dict[str, Any]:
        """
        Get current network metrics.
        
        Returns:
            Dictionary of network metrics
        """
        if not self.running:
            return {}
        
        # In a real implementation, this would return actual metrics
        # For now, we'll return the configured values with some random variation
        
        base_latency = self.current_config.get("latency_ms", 5)
        jitter = self.current_config.get("jitter_ms", 2)
        packet_loss = self.current_config.get("packet_loss_percent", 0)
        bandwidth = self.current_config.get("bandwidth_mbps", 1000)
        
        return {
            "latency_ms": max(0, base_latency + random.uniform(-jitter, jitter)),
            "packet_loss_percent": max(0, packet_loss + random.uniform(-0.5, 0.5)),
            "bandwidth_mbps": max(1, bandwidth + random.uniform(-bandwidth*0.1, bandwidth*0.1)),
            "jitter_ms": jitter
        }


class ResourceSimulator:
    """
    Simulates resource availability for deployment testing.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize the Resource Simulator.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config or {}
        self.current_config = {}
        self.running = False
    
    def configure(self, resource_config: Dict[str, Any]):
        """
        Configure the resource simulator.
        
        Args:
            resource_config: Resource configuration to apply
        """
        self.current_config = resource_config
    
    def start(self):
        """Start the resource simulator."""
        self.running = True
        logger.info(f"Started resource simulator with config: {self.current_config}")
    
    def stop(self):
        """Stop the resource simulator."""
        self.running = False
        logger.info("Stopped resource simulator")
    
    def get_metrics(self) -> Dict[str, Any]:
        """
        Get current resource metrics.
        
        Returns:
            Dictionary of resource metrics
        """
        if not self.running:
            return {}
        
        # In a real implementation, this would return actual metrics
        # For now, we'll return the configured values with some random variation
        
        cpu_available = self.current_config.get("cpu_available_percent", 80)
        memory_available = self.current_config.get("memory_available_percent", 80)
        storage_available = self.current_config.get("storage_available_percent", 80)
        
        return {
            "cpu_available_percent": max(0, min(100, cpu_available + random.uniform(-5, 5))),
            "memory_available_percent": max(0, min(100, memory_available + random.uniform(-5, 5))),
            "storage_available_percent": max(0, min(100, storage_available + random.uniform(-2, 2))),
            "cpu_usage_percent": max(0, min(100, 100 - (cpu_available + random.uniform(-5, 5)))),
            "memory_usage_percent": max(0, min(100, 100 - (memory_available + random.uniform(-5, 5)))),
            "storage_usage_percent": max(0, min(100, 100 - (storage_available + random.uniform(-2, 2))))
        }


class LoadGenerator:
    """
    Generates load for deployment testing.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize the Load Generator.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config or {}
        self.current_config = {}
        self.running = False
    
    def configure(self, load_config: Dict[str, Any]):
        """
        Configure the load generator.
        
        Args:
            load_config: Load configuration to apply
        """
        self.current_config = load_config
    
    def start(self):
        """Start the load generator."""
        self.running = True
        logger.info(f"Started load generator with config: {self.current_config}")
    
    def stop(self):
        """Stop the load generator."""
        self.running = False
        logger.info("Stopped load generator")
    
    def get_metrics(self) -> Dict[str, Any]:
        """
        Get current load metrics.
        
        Returns:
            Dictionary of load metrics
        """
        if not self.running:
            return {}
        
        # In a real implementation, this would return actual metrics
        # For now, we'll return the configured values with some random variation
        
        rps = self.current_config.get("requests_per_second", 100)
        users = self.current_config.get("concurrent_users", 50)
        data_transfer = self.current_config.get("data_transfer_mbps", 10)
        
        return {
            "requests_per_second": max(0, rps + random.uniform(-rps*0.1, rps*0.1)),
            "concurrent_users": max(0, users + random.uniform(-users*0.1, users*0.1)),
            "data_transfer_mbps": max(0, data_transfer + random.uniform(-data_transfer*0.1, data_transfer*0.1)),
            "response_success_rate": random.uniform(95, 100)
        }
